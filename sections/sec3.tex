\section{ROM Optimality Systems}

In the following, we want to consider optimality conditions for the reduced problem and from there deduce error estimates for the reduced problem..
This will involve primal and dual spaces for the conditions, causing the easily computable gradients that one would usually use to derive error estimates to differ from the exact gradients.
Only a short overview of the ideas mentioned will be given here, but a longer description can be found in~\cite[Section 3]{Keil2021}.
We then move on to state two different approaches to estimating the true gradients in the reduced problem.
Combining all this, we finally establish error estimates on the inexact functionals and their gradients.

If we consider~\eqref{StateEq} for our FOM and ROM problems~\eqref{FOMEq} and~\eqref{ROMEq}, we can see that the state equation can be restated through
\begin{equation*}
    e(u_\mu, \mu) = l_\mu(\cdot) - a_\mu(u_\mu, \cdot) \in V' \text{ or } V_N'.
\end{equation*}
We now define the \textbf{primal residual} by $Res_\mu^{pr}(u)[v] := l_\mu(v) - a_\mu(u, v)$.
Following~\cite[Corollary 1.3]{Hinze2009}, we get the optimality conditions in~\cite[Proposition 2.9]{Keil2021}, then derive from these the following dual relation
\begin{equation*}
    a_\mu(v, p_\mu) = \partial_u \mathcal{J}(u_\mu, \mu)[v] = j_\mu(v) + 2 k_\mu(v, u_\mu) \quad \forall v \in V \text{ or } V_N,
\end{equation*}
and finally define the \textbf{dual residual} in terms of the difference in the dual optimality condition $Res_\mu^{du}(u_\mu, p_\mu)[v] := j_\mu(v) + 2 k_\mu(v, u_\mu) - a_\mu(v, p_\mu)$.
By the same optimality conditions, all locally optimal points of~\eqref{OptiProb} have to satisfy
\begin{equation}\label{PrimalEq}
    Res_\mu^{pr}(u_\mu)[v] = 0 \qquad \forall v \in V \text{ or } V_N^{pr},
\end{equation}
and
\begin{equation}\label{DualEq}
    Res_\mu^{du}(u_\mu, p_\mu)[v] = 0 \qquad \forall v \in V \text{ or } V_N^{du}.
\end{equation}

In this and the following sections, $u_\mu$ will always denote the primal solution $u$ for some parameter $\mu$, and similarly $p_\mu$ the dual solution.
If necessary, we will denote the ROM solutions by $u_{N, \mu}$ ($p_{N, \mu}$ respectively), while we will avoid additional indices for the FOM solutions.

\subsection{Standard Approach for a ROM Optimality System}

We now introduce a first method to obtain an inexact gradient as proposed in~\cite{Qian2017} and specifically the variant described in~\cite[Subsection 3.2]{Keil2021}.
This method is practical because it enables the approximation of the exact gradient for the reduced solutions.
One particuliarity of this idea as mentioned by~\cite{Qian2017} is that we can afterwards disregard the usual offline/online paradigm during the optimization and thus adapt the reduced approximation on the fly.

We note here that as mentioned in~\cite[Subsection 3.2]{Keil2021} the primal and the dual spaces are in general not the same, even the dimensions may be assumed to differ.
Hence, for the reduced functional $J_N(\mu) := \mathcal{J}(u_{N, \mu}, \mu)$, when considering the gradients (or rather their componentwise definitions) we get
\begin{align}\label{Grads}
    {\big( \nabla_\mu J_N(\mu) \big)}_i &:= \partial_u \mathcal{L}(u_\mu, \mu, p)[d_{\mu_i} u_\mu] + \partial_{\mu_i} \mathcal{L}(u_\mu, \mu, p) \qquad \forall p \in V_N^{du}, \tag*{(exact)} \\
    {\big( \tilde{\nabla}_\mu J_N(\mu) \big)}_i &:= \partial_{\mu_i} \mathcal{J}(u_\mu, \mu) + \partial_{\mu_i} Res_\mu^{pr}(u_\mu)[p_\mu], \tag*{(inexact)}
\end{align}
where in the first line of equations we considered the Lagrangian for the reduced version of~\eqref{SettingOpti} and apply $J_N(\mu) = \mathcal{L}(u_\mu, \mu, p) \; \forall p \in V_N^{du}$.
If we then consider $p = p_\mu$ in the first line and combine them with the second line we obtain
\begin{equation*}\label{RelationGrads}
    {\big( \nabla_\mu J_N(\mu) \big)}_i = \underbrace{\partial_u \mathcal{L}(u_\mu, \mu, p)[d_{\mu_i} u_\mu]}_{(\ast)} + {\big( \tilde{\nabla}_\mu J_N(\mu) \big)}_i.
\end{equation*}
The key insight here is that in general $(\ast) \neq 0$ because we are not actually considering all elements from $V$ for~\eqref{DualEq}, but just those from the reduced dual space.

\subsection{NCD-corrected Approach for a ROM Optimality System}

To extend on the result of the previous section, the NCD-corrected reduced functional in~\cite[Subsection 3.3]{Keil2021} contains one more step to attain improved error estimates.
Specifically, this involves the restriction of the Lagrangian in the dual variable.
We get
\begin{equation}\label{NCDFunctional}
    \mathcal{J}_N(\mu) := \mathcal{L}(u_\mu, \mu, p_\mu) = J_N(\mu) + Res_\mu^{pr}(u_\mu)[p_\mu].
\end{equation}
This is the functional we will be dealing with forthwith, and we define the reduced optimization problem
\begin{equation}\label{ReducProb}
    \min\limits_{\mu \in \mathcal{P}} \mathcal{J}_N(\mu).
\end{equation}

The key insight for the coming error estimates is that the following statement (cf.~\cite[Proposition 3.3]{Keil2021}) about the gradient of~\eqref{NCDFunctional} holds true:
\begin{proposition}\label{NCDGradientProp}
    We have
    \begin{equation*}\label{NCDGradient}
        {\big( \nabla_\mu \mathcal{J}_N(\mu) \big)}_i = \partial_{\mu_i} \mathcal{J}(u_\mu, \mu) + \partial_{\mu_i} Res_\mu^{pr}(u_\mu)[p_\mu + w_\mu] - Res_\mu^{du}(u_\mu, p_\mu)[z_\mu],
    \end{equation*}
    where $z_\mu \in V_N^{du}$ and $w_\mu \in V_N^{pr}$ respectively denote the solutions to the following problems:
    \begin{align*}\label{NCDGradientZW}
        a_\mu(z_\mu, q) &= -Res_\mu^{pr}(u_\mu)[q] \qquad &&\forall q \in V_N^{du}, \text{ and} \\
        a_\mu(v, w_\mu) &= Res_\mu^{du}(u_\mu, p_\mu)[v] - 2 k_\mu(z_\mu, v) \qquad &&\forall v \in V_N^{pr}.
    \end{align*}
\end{proposition}

\todoinline{Add the prrof of this to the appendix!!!}

\subsection{\textit{A posteriori} error analysis}

\todoinline{Write paragraph for a posteriori errors!}