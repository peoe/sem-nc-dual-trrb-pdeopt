\section{Adaptive Trust-Region Reduced Basis Algorithm and Convergence}

\subsection{The TR-RB Algorithm}

\begin{frame}{TR-RB Algorithm}
    \begin{block}{Choice of Model Function}
        We choose
        \begin{equation*}
            m^{(k)}(\eta) := \mathcal{J}_N^{(k)}(\mu^{(k)} + \eta),
        \end{equation*}
        where $\eta \in \mathcal{P}$. \\~\\

        \only<2>{Note: $\mathcal{J}_N \neq \mathcal{J}_N^{(k)}$! These are based upon different spaces $V_N^{pr, k}, V_N^{du, k}$.}
    \end{block}
\end{frame}

\begin{frame}{TR-RB Algorithm}
    \only<1>{
        \begin{algorithm}[H]
            \While{not converged}{
                Compute locally optimal solution\;
                
                \If{some condition}{
                    Continue with refinement\;
                }
                \ElseIf{some other condition}{
                    Repeat optimization step with smaller domain\;
                }
                \ElseIf{some third condition}{
                    Refine and possibly repeat optimization step\;
                }
            }
        \end{algorithm}
    }

    \only<2>{
        \begin{algorithm}[H]
            \While{not converged}{
                Compute locally optimal solution\;
                
                \If{\color{red}$\mathcal{J}_N^{(k)}(\mu^{(k + 1)}) + \Delta_{\mathcal{J}_N^{(k)}}(\mu^{(k + 1)}) < \mathcal{J}_N^{(k)}(\mu^{(k)})$}{
                    Continue with refinement\;
                }
                \ElseIf{some other condition}{
                    Repeat optimization step with smaller domain\;
                }
                \ElseIf{some third condition}{
                    Refine and possibly repeat optimization step\;
                }
            }
        \end{algorithm}
    }

    \only<3>{
        \begin{algorithm}[H]
            \While{not converged}{
                Compute locally optimal solution\;
                
                \If{\color{red}decrease suffienctly small}{
                    Continue with refinement\;
                }
                \ElseIf{some other condition}{
                    Repeat optimization step with smaller domain\;
                }
                \ElseIf{some third condition}{
                    Refine and possibly repeat optimization step\;
                }
            }
        \end{algorithm}
    }

    \only<4>{
        \begin{algorithm}[H]
            \While{not converged}{
                Compute locally optimal solution\;
                
                \If{decrease suffienctly small}{
                    Continue with refinement\;
                }
                \ElseIf{\color{red}$\mathcal{J}_N^{(k)}(\mu^{(k + 1)}) + \Delta_{\mathcal{J}_N^{(k)}}(\mu^{(k + 1)}) > \mathcal{J}_N^{(k)}(\mu^{(k)})$}{
                    Repeat optimization step with smaller domain\;
                }
                \ElseIf{some third condition}{
                    Refine and possibly repeat optimization step\;
                }
            }
        \end{algorithm}
    }

    \only<5>{
        \begin{algorithm}[H]
            \While{not converged}{
                Compute locally optimal solution\;
                
                \If{decrease suffienctly small}{
                    Continue with refinement\;
                }
                \ElseIf{\color{red}decrease not small enough}{
                    Repeat optimization step with smaller domain\;
                }
                \ElseIf{some third condition}{
                    Refine and possibly repeat optimization step\;
                }
            }
        \end{algorithm}
    }

    \only<6>{
        \begin{algorithm}[H]
            \While{not converged}{
                Compute locally optimal solution\;
                
                \If{decrease suffienctly small}{
                    Continue with refinement\;
                }
                \ElseIf{decrease not small enough}{
                    Repeat optimization step with smaller domain\;
                }
                \Else{
                    Refine and possibly repeat optimization step\;
                }
            }
        \end{algorithm}
    }

    \only<7>{
        \begin{algorithm}[H]
            \While{not converged}{
                Compute locally optimal solution\;
                
                \If{decrease suffienctly small}{
                    \color{red} Refine and potentially enlarge trust-radius\;
                }
                \ElseIf{decrease not small enough}{
                    \color{red} Repeat optimization step with smaller domain\;
                }
                \Else{
                    \color{red} Refine and check whether to repeat optimization (shrinking, enlarging, or keeping of trust-radius depending on outcome)\;
                }
            }
        \end{algorithm}
    }
\end{frame}

\subsection{Convergence of the TR-RB Algorithm}

\begin{frame}{Overview on Convergence}
    \begin{block}{Remarks on the Proof}
        \begin{itemize}
            \item $\mathcal{P}$ is compact.
            \item In~\cite{Keil2021}, the proof is very short; in~\cite{Qian2017} more explicit versions can be found.
            \only<2>{\item Proper \textbf{convergence is not shown}, just that ``all accumulation points of the sequence of parameters are first order critical points''!}
        \end{itemize}
    \end{block}
\end{frame}

\begin{frame}{Convergence Arguments}
    \only<1>{
        \begin{block}{General Idea, c.f.~\cite{Qian2017}}
            For the TR method to converge we require that
            \begin{enumerate}
                \item the error of $m^{(k)}$ can be bounded over all of $\mathcal{P}$,
                \item at any $\mu \in \mathcal{P}$ we can reduce the approximation error of $m^{(k)}$ to some small tolerance $\varepsilon > 0$, and
                \item $m^{(k)}$ is smooth with a finite gradient everywhere.
            \end{enumerate}
        \end{block}
    }

    \only<2, 3>{
        \begin{block}{Specific Formulations, c.f.~\cite{Qian2017}}
            For our problem we get
            \begin{itemize}
                \item $\abs{\mathcal{J}(u_\mu, \mu) - \mathcal{J}_N(\mu)} \leq \Delta_{\mathcal{J}_N}(\mu)$,
                \item $\norm[2]{\nabla_\mu \mathcal{J}(u_\mu, \mu) - \nabla_\mu \mathcal{J}_N(\mu)} \leq \Delta_{\nabla \mathcal{J}_N}(\mu)$, and
                \item $\mathcal{J}_N^{(k + 1)}(\mu^{(k + 1)}) \leq \mathcal{J}_N^{(k)}(\mu^{(k, 0)})$.
            \end{itemize}
        \end{block}
    }

    \only<3>{
        The last is equivalent to
        \begin{equation*}
            \mathcal{J}_N^{(k)}(\mu^{(k + 1)}) + \Delta_{\mathcal{J}_N^{(k)}}(\mu^{(k + 1)}) < \mathcal{J}_N^{(k)}(\mu^{(k)}).
        \end{equation*}
    }
\end{frame}

\begin{frame}{Convergence Arguments}
    \begin{block}{Assumptions}
        \begin{itemize}
            \item $\mathcal{J}(u, \mu)$ is strictly positive.
            \item For every TR iteration $k$ we can find a trust-radius large enough for which the decrease
        \end{itemize}
    \end{block}

    \only<2, 3>{
        \begin{block}{Result 1}
            The line search for a parameter in the trust-region takes finitely many iterations to complete.
        \end{block}
    }

    \only<3>{
        \begin{block}{Block 2}
            Every accumulation point of $\mu^{(k)}$ are first order critical points.
        \end{block}
    }
\end{frame}

\begin{frame}{Convergence Arguments}
    zxcv~\cite{Banholzer2020}
\end{frame}