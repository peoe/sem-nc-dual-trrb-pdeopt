\section{Adaptive Trust-Region Reduced Basis Algorithm and Convergence}

\subsection{The TR-RB Algorithm}

\begin{frame}{TR-RB Algorithm}
    \begin{block}{Choice of Model Function}
        We choose
        \begin{equation*}
            m^{(k)}(\eta) := \mathcal{J}_N^{(k)}(\mu^{(k)} + \eta),
        \end{equation*}
        where $\eta \in \mathcal{P}$. \\~\\

        Note: $\mathcal{J}_N^{(k)}$ are based upon different spaces $V_N^{pr, k}, V_N^{du, k}$.
    \end{block}
\end{frame}

\begin{frame}{TR-RB Algorithm}
    \only<1>{
        \begin{algorithm}[H]
            \While{not converged}{
                Compute locally optimal solution\;
                
                \If{some condition}{
                    Continue with refinement\;
                }
                \ElseIf{some other condition}{
                    Repeat optimization step with smaller domain\;
                }
                \ElseIf{some third condition}{
                    Refine and possibly repeat optimization step\;
                }
            }
        \end{algorithm}
    }

    \only<2>{
        \begin{algorithm}[H]
            \While{not converged}{
                Compute locally optimal solution\;
                
                \If{\color{red}$\mathcal{J}_N^{(k)}(\mu^{(k + 1)}) + \Delta_{\mathcal{J}_N^{(k)}}(\mu^{(k + 1)}) < \mathcal{J}_N^{(k)}(\mu^{(k)})$}{
                    Continue with refinement\;
                }
                \ElseIf{some other condition}{
                    Repeat optimization step with smaller domain\;
                }
                \ElseIf{some third condition}{
                    Refine and possibly repeat optimization step\;
                }
            }
        \end{algorithm}
    }

    \only<3>{
        \begin{algorithm}[H]
            \While{not converged}{
                Compute locally optimal solution\;
                
                \If{\color{red}output decrease sufficiently small}{
                    Continue with refinement\;
                }
                \ElseIf{some other condition}{
                    Repeat optimization step with smaller domain\;
                }
                \ElseIf{some third condition}{
                    Refine and possibly repeat optimization step\;
                }
            }
        \end{algorithm}
    }

    \only<4>{
        \begin{algorithm}[H]
            \While{not converged}{
                Compute locally optimal solution\;
                
                \If{output decrease sufficiently small}{
                    Continue with refinement\;
                }
                \ElseIf{\color{red}$\mathcal{J}_N^{(k)}(\mu^{(k + 1)}) + \Delta_{\mathcal{J}_N^{(k)}}(\mu^{(k + 1)}) > \mathcal{J}_N^{(k)}(\mu^{(k)})$}{
                    Repeat optimization step with smaller domain\;
                }
                \ElseIf{some third condition}{
                    Refine and possibly repeat optimization step\;
                }
            }
        \end{algorithm}
    }

    \only<5>{
        \begin{algorithm}[H]
            \While{not converged}{
                Compute locally optimal solution\;
                
                \If{output decrease sufficiently small}{
                    Continue with refinement\;
                }
                \ElseIf{\color{red}output decrease not small enough}{
                    Repeat optimization step with smaller domain\;
                }
                \ElseIf{some third condition}{
                    Refine and possibly repeat optimization step\;
                }
            }
        \end{algorithm}
    }

    \only<6>{
        \begin{algorithm}[H]
            \While{not converged}{
                Compute locally optimal solution\;
                
                \If{output decrease sufficiently small}{
                    Continue with refinement\;
                }
                \ElseIf{output decrease not small enough}{
                    Repeat optimization step with smaller domain\;
                }
                \Else{
                    Refine and possibly repeat optimization step\;
                }
            }
        \end{algorithm}
    }

    \only<7>{
        \begin{algorithm}[H]
            \While{not converged}{
                Compute locally optimal solution\;
                
                \If{output decrease sufficiently small}{
                    \color{red} Refine and potentially enlarge trust-radius\;
                }
                \ElseIf{output decrease not small enough}{
                    Repeat optimization step with smaller domain\;
                }
                \Else{
                    \color{red} Refine and check whether to repeat optimization (shrinking, enlarging, or keeping of trust-radius depending on outcome)\;
                }
            }
        \end{algorithm}
    }
\end{frame}

\begin{frame}{TR-RB Algorithm}
    \begin{block}{Inner Loop (BFGS), c.f.~\cite{Qian2017, Keil2021}}
        The inner (BFGS) step is
        \begin{equation*}
            \mu^{(k, l + 1)} := \mu^{(k, l)}(j) := \mathbb{P}(\mu^{(k, l)} + \kappa^j d^{(k, l)}),
        \end{equation*}
        where
        \begin{equation*}
            {\mathbb{P}(\mu)}_i := \begin{cases}
                {(\mu_a)}_i, {(\mu)}_i \leq {(\mu_a)}_i, \\
                {(\mu)}_i, {(\mu_a)}_i \leq {(\mu)}_i \leq {(\mu_b)}_i, \\
                {(\mu_b)}_i, {(\mu_b)}_i \leq {(\mu)}_i
            \end{cases}.
        \end{equation*}
        Finally,
        \begin{equation*}
            \mu^{(k + 1)} := \mu^{(k, L)}.
        \end{equation*}
    \end{block}
\end{frame}

\subsection{Convergence of the TR-RB Algorithm}

\begin{frame}{Overview on Convergence}
    We have:
    \begin{block}{}
        All accumulation points of the sequence of parameters are approximate first order critical points.
    \end{block}
\end{frame}