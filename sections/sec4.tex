\section{Adaptive Enrichment for Trust-Region Reduced Basis Approximation}

The objective of this section is to describe the trust-region reduced basis method described in~\cite[Section 4]{Keil2021}.
To this end we shall stick to a general description, and only mention the relevant theoretical results for convergence at the end.
Throughout we shall choose the model function (cf. Subsection~\ref{subsec:TRRB}) to be defined as the sequence indexed by $k \geq 0$ as follows
\begin{equation*}\label{TRModelFunc}
    m^{(k)}(\eta) := \mathcal{J}_N(\mu^{(k)} + \eta).
\end{equation*}
The reduced spaces are assumed to be initialized as $V_N^{pr, 0} = \{ u_\mu \}, V_N^{du, 0} = \{ p_\mu \}$, with $u_\mu$ and $p_\mu$ being the FOM solutions for some initial guess $\mu^{(0)} \in \mathcal{P}$.
We can then state the inexact reduced version of~\eqref{TROpti} as introduced in~\cite[Equation 51]{Qian2017}
\begin{equation}\label{TRInexactOpti}
    \min\limits_{s \in \mathcal{P}} \mathcal{J}_N(\mu^{(k)} + s) \quad \text{s.t.} \quad \frac{\Delta_{\mathcal{J}_N}(\mu^{(k)} + s)}{\mathcal{J}_N(\mu^{(k)} + s)} \leq \delta^{(k)},
\end{equation}
where the equality constraint $Res_{\mu^{(k)} + s}^{pr} (u_{N, \mu^{(k)} + s})[v] = 0$ is hidden in $\mathcal{J}_N$, and $\delta^{(k)}$ is the radius of the trust-region.

For every step of the trust-region method we then have to solve the local problem via BFGS.\@
For the first iteration we need to define the \textbf{approximate general Cauchy point} (AGC).
This point is defined by
\begin{equation*}\label{AGCPoint}
    \mu_{AGC}^{(k)} := \mu^{(k, 0)}(j^{(k, 0)}) = \mathbb{P}_{\mathcal{P}} \left( \mu^{(k, 0)} + \kappa^{j^{(k, 0)}} d^{(k, 0)} \right),
\end{equation*}
where $\mathbb{P}_\mathcal{P}$ is the projection ${\left( \mathbb{P}_\mathcal{P}(\mu) \right)}_i := \begin{cases}
    {(\mu_a)}_i, {(\mu)}_i \leq {(\mu_a)}_i, \\
    {(\mu)}_i, {(\mu_a)}_i \leq {(\mu)}_i \leq {(\mu_b)}_i, \\
    {(\mu_b)}_i, {(\mu_b)}_i \leq {(\mu)}_i,
\end{cases}$
mapping the parameters into the rectangular bounds $\mathcal{P}$ in analogy to the projection described in Subsection~\ref{subsec:TRRB}.
Here the initial descent direction is $d^{(k, 0)} = - \nabla_\mu \mathcal{J}(\mu^{(k, 0)})$, and $j^{(k)}$ is the smallest integer such that the Armijo condition in~\cite[Inequality 4.4]{Keil2021} and the trust-region inequality condition from~\eqref{TRInexactOpti} (cf.~\cite[Inequality 4.5]{Keil2021}).
We then iterate via
\begin{align*}
    \mu^{(k, l)}(j^{(k, l)}) &:= \mathbb{P}_\mathcal{P} \left( \mu^{(k, 0)} + \kappa^{j^{(k, l)}} d^{(k, 0)} \right), \\
    \mu^{(k, l+ 1)} &:= \mu^{(k, l)}(j_k^{(l)})
\end{align*}
with this $j$ once again satisfying the same conditions for the indices $k, l$.
After the termination condition for the BFGS method has been reached at $L$ iterations, see~\cite[Inequalities 4.6a and 4.6b]{Keil2021}, we set $\mu^{(k + 1)} := \mu^{(k, L)}$ for the next (potential) trust-region iteration.

\todoinline{Write paragraph for enlarging trust radius}

\todoinline{Write paragraph for reduced space construction}

\todoinline{Write down shortened version of algorithm}

\todoinline{Write short remark for convergence + insights of the next paper}