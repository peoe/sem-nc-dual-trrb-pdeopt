\section{Preliminaries}

\todoinline{Write introductory paragraph}

\subsection{Reduced Basis Method}

This section introduces the reduced basis method (RBM) motivated by a consideration of parametrized PDEs with a large number of parameters.
This might be the case in optimization, parameter identification or other similar multi-query scenarios where the repeated computation might otherwise be too expensive.
A quick overview of RBM the reduced basis method will be given here, while its advantages, limitations, and challenges can be found in works such as~\cite{Ohlberger2015},~\cite{Quarteroni2015} or~\cite{Hesthaven2016}.

We start off with a generic description of the finite element method.
The central problem for this method is to find some $u \in V$ such that the following equation may be satisfied
\begin{equation}\label{FOMEq}
    a_\mu(u, v) = l_\mu(v) \qquad \forall v \in V,
\end{equation}
where $a_\mu$ is a continuous, coercive, bilinear form and $l_\mu$ is a continuous linear functional on some function space $V$.
In general, $V$ is supposed to be a high dimensional function space used to obtain a model with negligible error when compared to the true solution.
This model is called the full order model (FOM).
We note here that the resulting system of equations is far too expensive to compute for mutliple parameter values in sequence, motivating the introduction of RBM.\@

The first step is to only consider a certain $N$-dimensional subspace $V_N \subseteq V$ of the FOM space, where $N << \dim(V)$.
As a result the problem we want to solve is to find some $u_N \in V_N$ such that
\begin{equation}\label{ROMEq}
    a_\mu(u_N, v) = l_\mu(v) \qquad \forall v \in V_N,
\end{equation}
is satisfied.
Thus far, the complexity to solve this problem for multiple parameters has been reduced, however we can do even better.
The key assumption to acheive this is the so-called \textbf{parameter-separability}.
This means that we can decompose $a_\mu$ and $l_\mu$ in the following manner
\begin{equation}\label{ParamSep}
    a_\mu(u, v) = \sum\limits_{p = 1}^{p_a} \theta_p^a(\mu) \, a_p(u, v), \qquad l_\mu(v) = \sum\limits_{p = 1}^{p_l} \theta_p^l(\mu) \, l_p(v),
\end{equation}
where the $\theta$ are parameter functions for $a_\mu$ and $l_\mu$ respectively, the $p$ are the number of parameters for $a_\mu$ and $l_\mu$ respectively, and the $a_p$ and $l_p$ are the parameter independent components for $a_\mu$ and $l_\mu$ respectively.

With this assumption in hand, we can introduce the idea which enables RBM to repeatedly compute the solution for different parameters: the \textbf{offline/online decomposition}.
The principal idea is to first assemble the parameter independent system of equations and later only compute the parameter dependent parts for each parameter.
In this procedure, the computationally complex assembly is done only once (\textbf{offline phase}), while the computationally faster addition of parameters can be cheaply repeated multiple times (\textbf{online phase}).
We thus assemble
\begin{align*}\label{OffOnComp}
    &\mathbb{A}^{i, j}_m := a_m(\varphi_j, \varphi_i), &&\mathbb{L}^i_n := l_n(\varphi_i), \tag*{(offline)} \\
    &\mathbb{A}(\mu) := \sum\limits_{p = 1}^{p_a} \theta_p^a(\mu)\, \mathbb{A}_p, &&\mathbb{L}(\mu) := \sum\limits_{p = 1}^{p_l} \theta_p^l(\mu)\, \mathbb{L}_p, \tag*{(online)}
\end{align*}
for some basis $\{ \varphi_i \; | \; 1 \leq i \leq N \}$ of the space $V_N$, $1 \leq m \leq p_a$, and $1 \leq n \leq p_l$.
We can afterwards obtain our solution by solving the system
\begin{equation*}\label{OnOffSystem}
    \mathbb{A}(\mu)\, \underbar{u}_N(\mu) = \mathbb{L}(\mu), \qquad u_N(\mu) = \sum\limits_{i = 1}^N \underbar{u}_N(\mu)\, \varphi_i.
\end{equation*}

Overall this approach via offline/online decomposition requires a complexity of $\mathcal{O}(N^2 \, p_a) + \mathcal{O}(N \, p_l) + \mathcal{O}(N^3) + \mathcal{O}(N)$, where the first two terms amount to the offline assembly, the third summand originates from solving the assembled system, and the linear term is due to the reassembly of the solution from the solution vector.

One essential question in RBM is the construction of the reduced space $V_N$. For this there are multiple methods such as:
\begin{itemize}
    \item Greedy algorithm: construction of the reduced basis by choosing the parameter solution with the largest \textit{a posteriori} error, cf.~\cite{DeVore2013, Veroy2003},
    \item Proper orthogonal decomposition: construction of the reduced basis by left singular values, cf.~\cite{Kunisch2001, Haasdonk2008}, and
    \item Discrete empirical interpolation: construction of the reduced basis by finding a unisolvent set for an interpolation operator, cf.~\cite{Barrault2004, Carlberg2011, Chaturantabut2010, Drohmann2012}.
\end{itemize}

\subsection{PDE Constrained Optimization}

We now want to introduce the idea of optimization under PDE constraints.
This type of optimization is similar to other kinds of optimization in that we can derive certain optimality conditions reliant on the gradient and Hessian of some function or functional.
When working functionals it is required that we take care in describing how the derivatives of these functionals are defined and calculated.
Hence we first give the definitions of \textbf{G\^{a}teaux} and \textbf{Fr\'{e}chet differentiability} in accordance with~\cite[Section 1.4]{Hinze2009}.

A functional $F: X \rightarrow Y$ is called G\^{a}teaux differentiable at $x \in X$ if the directional derivative $dF(x): X \rightarrow Y, h \mapsto dF (x) [ h ]$ is a bounded and linear functional, that is $dF(x) \in \mathcal{L}(X, Y)$, where the directional derivative of $F$ at $x$ is defined by
\begin{equation*}\label{DirDeriv}
    dF(x)[h] := \lim\limits_{t \rightarrow 0} \frac{F(x + th) - F(x)}{t} \in Y.
\end{equation*}
If furthermore the approximation
\begin{equation*}\label{FrechDeriv}
    \norm[Y]{F(x + th) - F(x) - dF(x)[h]} = o(\norm[X]{h})
\end{equation*}
holds for $\norm[X]{h} \rightarrow 0$, we say that $F$ is Fr\'{e}chet differentiable at $x$.
The usual generalization to say that $F$ is G\^{a}teaux/Fr\'{e}chet differentiable if it is G\^{a}teaux/Fr\'{e}chet differentiable at every $x \in X$ also applies here.

For our use case we often consider parametrized functionals, for which we get the chain rule
\begin{align*}
    d_\mu a_\mu(u_\mu, v_\mu) \cdot \nu &= \partial_\mu a_\mu(u_\mu, v_\mu) \cdot \nu + \partial_u a_\mu(u_\mu, v_\mu)[d_\nu u_\mu] + \partial_v a_\mu(u_\mu, v_\mu)[d_\nu v_\mu] \\
    &= \partial_\mu a_\mu(u_\mu, v_\mu) \cdot \nu + a_\mu(d_\nu u_\mu) + a_\mu(u_\mu, d_\nu v_\mu),
\end{align*}
where we generally denote the derivative w.r.t.\@ to the parameter with $\partial_\mu$ and the derivative w.r.t.\@ the respective first and second argument with $\partial_u$, and $\partial_v$.

For the scope of this seminar, we shall consider problems of the form
\begin{equation}\label{OptiProb}
    \min\limits_{u \in V, \mu \in \mathcal{P}} J(u, \mu) \quad s.t. \quad e(u, \mu) = 0,
\end{equation}
where we consider $V$ to be some function space, and $\mathcal{P}$ to be the underlying parameter space.
In accordance with~\cite[Subsection 1.1.1 and Equation 1.4; Section 1.6 and Equation 1.81]{Hinze2009}, we call the function $J$ the \textbf{objective function} and
\begin{equation}\label{StateEq}
    e(u, \mu) = 0
\end{equation}
the \textbf{state equation}.

We can then derive a system of optimality condition for~\eqref{OptiProb}, similarly to~\cite[Section 1.7]{Hinze2009}.
However, this will be covered later on in direct application to our general problem setting.

\subsection{Trust-Region Method and BFGS}

For the final component of this seminar we take a look at the trust-region method.
The benefit of this method is that we can iteratively perform local optimizations for a simpler function than our initial objective function.
The general procedure according to~\cite[Section 3.3]{Kelley1999} is to approximate the objective function by a quadratic model function $m_k$ in a region where we can trust that this approximation is of sufficient quality --- the so-called \textbf{trust-region}.

Any such trust-region can be described by $\Delta_k := \{ x \in X \; | \; \norm{x - x_k} \leq \delta_k \}$, where $x_k$ is the sequence of points obtained from our iterative optimization procedure and $\delta_k$ is the radius of the current trust-region.
We then optimize over the trust-region and compute the next $x_k$ as follows:
\begin{equation}\label{TROpti}
    s_k := \argmin\limits_{\norm{s} \leq \delta_k} m_k(x_k + s) \qquad x_{k + 1} := x_k + s_k.
\end{equation}
Afterwards, we can decide whether or not to accept this step subject to conditions depending on the individual problem such as accuracy of the underlying model function or satisfaction of other previously given constraints.
Depending on the decision taken here, we are left with two options:
\begin{itemize}
    \item if the step is rejected we may decrease the trust-radius and repeat the optimization, and
    \item if the step is accepted and a certain threshold reached we may increase the trust-radius and proceed with the next trust-region.
\end{itemize}
This behaviour will later be used to adaptively refine our underlying space $V_N$ and perform a TR algorithm at the same time.

In each iteration of the trust-region method we have to solve~\eqref{TROpti} for a certain trust-region.
For this matter we involve the BFGS method (Broyden, Fletcher, Goldfarb, Shanno) is a quasi-Newton method where we perform a line search with some approximation of the Hessian for the Newton steps, cf.~\cite[Chapter 4]{Kelley1999}.
The iterations in~\cite{Keil2021} then appear as follows:
\begin{equation*}\label{BFGSStep}
    \mu_{k+1}(j) := \mathbb{P}_{\mathcal{P}} \left( \mu_k + \kappa^j \, d_k \right),
\end{equation*}
where $d$ denotes the descent direction, $\kappa \in (0, 1)$ is a step size, and $\mathbb{P}$ is the projection operator which ensures that our iterator remains within our constraint domain.
The descent direction here is determined as outlined in~\cite[Section 5.5.3]{Kelley1999}.
We then terminate this iteration at some point to compute the next TR.\@